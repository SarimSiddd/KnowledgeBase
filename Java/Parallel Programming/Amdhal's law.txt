https://www.coursera.org/learn/parallel-programming-in-java/supplement/PU294/1-5-lecture-summary


Lecture  Summary:  In this lecture,  we  studied a simple observation made by  Gene Amdahl in 1967: if q ≤ 1 is the fraction of WORK in a parallel program that must be executed sequentially, then the best speedup that can be obtained for that program for any number of processors, P , is Speedup(P)≤ 1/q.

This observation follows directly from a lower bound on parallel execution time that you are familiar with, namely T_P 
P
​
 ≥ SPAN(G). If fraction q of WORK(G) is sequential, it must be the case that SPAN(G) ≥ q  × WORK(G).   Therefore,  Speedup(P)  = T_1 
1
​
 /T_P 
P
​
  must be  ≤  WORK(G)/(q × WORK(G))  = 1/q since T_1 
1
​
  = WORK(G) for greedy schedulers.

Amdahl’s Law reminds us to watch out for sequential bottlenecks both when designing parallel algorithms and when implementing programs on real machines.  As an example, if q = 10%, then Amdahl's Law reminds us that the best possible speedup must be ≤ 10 (which equals 1/q ), regardless of the number of processors available.